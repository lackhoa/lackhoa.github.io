---
title: "AI will destroy human society, and we can't stop it"
---

{% raw %}

I ran out of nerdy, technical things to write about, so let's talk something philosophical tonight.
I don't know if these ideas are new, but they are already covered in modern literature, and I haven't read lots of books so I don't know for sure.

Maybe they are wrong ideas.
But at least I haven't heard anything in public discourse that are clearly in this direction.
Perhaps if you even dare to start thinking like this, you're instantaneously be banished to the shadow realm and never see the light of day again. We'll see...

# What's the definition of "Good"?

When I was a kid, my definition of "good" was simple: to be polite, to be kind, to respect elders, to work hard, etc.
These are worthy goals for a kid.
You see, children are impulsive: they are rude, they are lazy and selfish too.
So if a child can master those virtues such as I listed, that child is good.

But actually that raises a question: "why are those specific virtues desirable?"
Well, it's because if I have a child, I would want that child to be well-behaved (i.e to not cause trouble for others).

Of course, this goodness criteria isn't just some straw-man.
I don't think you can get much better virtues anywhere else.
At most you can find macho-refinements such as "be strong, don't be naive".
However, the underlying aim of these virtues are pretty much the same: "Be strong so that you can protect the weak, not to assert dominance".

At some point, I realized that being virtuous isn't enough anymore.
If you're rich, it doesn't take a genius to be polite, after all you only need to converse with your equally wealthy friends.
It's not hard to donate a bit of money to charity every month.
You can afford to dedicate yourself to your work if you have stability in your economic and social situation.

Perhaps that's why some people are (understandably) upset at rich people.
You can't just have these unfair advantages?
You're supposed to grow up poor, work hard and be a self-made man/woman.
You're not supposed to be handed down wealth from birth.

Yeah, because then, only *then* you have an opportunity to work hard.
Only when you're starving and freezing will it be difficult to care for others.
Only when facing barbarians will it be difficult to hold a civil conversation.
Only when your situation is hopeless is it hard to get yourself together and strive for a better future.

So virtues by themselves aren't good, they have to be fought for.

Because if everyone can be good, there is no Good.

---

[Blessed are you who are poor, for yours is the kingdom of God.](https://biblehub.com/luke/6-20.htm)

[If you do good to those who do good to you, what credit is that to you? Even sinners do the same.](https://biblehub.com/luke/6-33.htm)

---

Well shoot! Should we then strive towards poverty?
Should we make more fire to then put them out?
Apparently that's how God wants humanity to be.
That's why He created these obstacles for us to conquer.

Well, the only problem is that we're starting to win.
Initially people roamed out hunting and gathering.
Then they learned to grow crops and raised cattles.
Manual labor is difficult? We have machines do our work for us.
Keeping track of things is difficult? We have computers to do the computation.
Programming computers is difficult? We have AI to take care of even that.

AI happens to also solve every remaining problems that you have, so long as you have a good specification of the problem.
All that remains for man is to conjure up the problem, and the machine will take care of solving it.
You can help it solve the problem if you want, but there's no need.
You can try solve the problem yourself, but you're gonna be 10000x slower.
So let's just lie back and let the AI take care of it, will ya?

# But this is just a fantasy, right?

I'm not so sure about that.
Right now it is hard to make people rich.
There are still plenty of suffering in the world.

But what if through technological progress, we eliminate poverty completely?
What if nobody had to work anymore?
That would be the Socialist utopia: "From each according to his ability, to each according to his needs", minus the "from each" part because you don't need to do anything.

# Sexual reproduction

What if people just don't have to be good anymore to survive?
Unfit? Totally fine, you don't have to move.
Unintelligent? AI takes care of all the thinking for you.
Unattrative? Well, beauty is subjective after all.

Other folks have already talked about this:

- [Unabomber Manifesto 122.](https://www.washingtonpost.com/wp-srv/national/longterm/unabomber/manifesto.text.htm)
- [Mice utopia](https://youtu.be/NgGLFozNM2o)

The gist of it is: if there is no environmental pressure on sexual reproduction, the human gene pool will become corrupt.
This is the unevitable outcome that frightens me to the core.

# What about art?

Art will be gone, too.

It's the same problem: when you don't have a hierarchy of values, beauty doesn't exist.
Why is the [David](https://en.wikipedia.org/wiki/David_(Michelangelo)) a masterpiece?
Because it depicts a human ideal: a man that is fit, attentive, and is facing his intimidating adversary Goliath.
Well it follows that if you no longer have the same ideals, beauty will change its form.

It's not unfathomable that future humans will see a fat David, a bored David, or a gay David (I'm perfectly fine with a gay David btw, the others not so much).

# So what do we do about it?

We could shut down the Machine Learning compute cluster and call it a day.
Just shut down the whole thing and pretend it never happened.
Except that... China is gonna have AI, North Korea is gonna have AI.
Like nuclear weapons, we need AI to defend ourselves from other AI.

Many people expressed concern that "AI is gonna kill us all".
Because they are uncontrollable, and uncontrollable things with great power tend to explode in our faces.

However, I'm not even worried about even that, so what if AI *was* controllable?
So what if we can bend them to our free will?
It doesn't matter, when people stop needing other people, they will stop caring about other people.

Furthermore, even the entire world would come together and decide to play the game of primitive society.
There will be plenty of great games to play *within* the technological utopia.
I don't suspect many people playing games like World of Warcraft would actually want to live in the middle ages.
Most people playing GTA never dare to become criminals themselves.
Because... why risk your life when you can just experience virtual reality in a video game?
If it's undistinguishable from reality, it is real enough to me.

There is just a final point I'd like to make, and this is the strongest point: You cannot curb progress, period.
What are you gonna tell the honest people who work their hardest to make the world a better place?
What do you tell doctors who work tirelessly to save lives?
That their jobs can be easily automated by machines, but we're not gonna do it in fear of a societal crisis?
You're gonna tell them to keep toiling away like the obedient ants they are, in exchange for some cash and comfort?

To those who answered "yes": Fuck you.
You are manipulative, arrogant, and you don't understand the first thing about human beings.

# Conclusion

So when is society gonna collapse?
Well, the exact timeline of the AI Singularity doesn't matter.
Because society won't collapse immediately after then.
Chess didn't get any less popular after Deep Blue.
And people still compete in Tennis tournaments even though Serving machines exist.
And that is completely *good*, but eventually people will stop caring about *meaningless* games like that, because there is an infinite amount of things to care about and the probability that people 10000 years from now will care about the same thing we do today is so small that it's practically nothing.

Given the doomy outlook, am I sad and discouraged?
Well... absolutely not.
I still have my values, and things I wanna do.
However, I just think that there's no reason to worship these values.
They happen to just work right now, but they will be gone in a distant future.

Furthermore, I'm not convinced by rational thoughts, mainly not because they might be wrong, but because I might miss some things.
Life is complex, I don't understand much of it.

In fact I *do* know a space where AI can't reach, and that is philosophy, particularly those related to personal understanding.
Because how is Machine Learning gonna solve philosophical issues?
You can't train an AI to understand me because there is only one *me*.
There is, by definition, no data to train on.
The only way to figure out who I am is for me to experience life, and honestly convey my own thoughts.

Anyway, it's not the time to worry about these issues.
We are fine for now, and for a long time.

{% endraw %}
